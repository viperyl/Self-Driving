{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Line Finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Targets of pipeline:\n",
    "* Identify the position of the lane lines\n",
    "* Find the location of the vehicle relative to the center of the lane\n",
    "* Find the radius of curvature of the road\n",
    "\n",
    "The main steps of pipeline:\n",
    "* **Step1:** Compute the camera calibration matrix and distortion coefficients\n",
    "* **Step2:** Apply a distortion correction to raw images\n",
    "* **Step3:** Use color transform and gradient decent methods to create a threshold binary image\n",
    "* **Step4:** Apply perspective transform to rectify binary image \n",
    "* **Step5:** Dectect lane pixels and fit to find lane boundary\n",
    "* **Step6:** Determine the curvature of the lane and vehicle position with respect to cener\n",
    "* **Step7:** Warp the detected lane boundaries back onto the original image\n",
    "* **Step8:** Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1&2: Camera Calibration\n",
    "\n",
    "The camera has radial distortion and tangential distortion. In order to correct these optical distrotion, we need to compute the camera matrix using several object points and image points. The image points are detectedd as chess board corners and the object points are just the coordinates of the chess board . I used the opencv function findChessboardCorners and undistort to perform camera calibration. Here is a comparison of the original image and the reviced image:\n",
    "[![VN1a2d.png](https://s2.ax1x.com/2019/06/05/VN1a2d.png)](https://imgchr.com/i/VN1a2d)\n",
    "[![VN1dxA.png](https://s2.ax1x.com/2019/06/05/VN1dxA.png)](https://imgchr.com/i/VN1dxA)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3: Apply Binary Thresholds\n",
    "In orde to \n",
    "Then I use color gradient and color threshold to produce binary images for further detection. There are many methods and parameters to choose such as color gradient along x direction and y direction. RGB color threshold and HLS threshold. After a series of experimetns and parameter turning, I ended up to select yellow lane lines and whie lane lines separately and combined them at the end. This method is more robust to shadow and differeent lightness conditions compared with color gradient method. RGB color space and Lab color space when chose for the color selection. RGB color space and Lab color space were chosen for the color selection. The result of a test is like followign:\n",
    "[![VN1qG4.md.png](https://s2.ax1x.com/2019/06/05/VN1qG4.md.png)](https://imgchr.com/i/VN1qG4)\n",
    "[![VN1jMR.md.png](https://s2.ax1x.com/2019/06/05/VN1jMR.md.png)](https://imgchr.com/i/VN1jMR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4: Perspective Transformation\n",
    "To achieve tge perspective transformation, I first applied tge getPerspectiveTransform and warpPerspective which take a matrix of four source points on the undistorted image and remaps them to four destination points on the warped image.\n",
    "After perspective transform, the warpped image looks like this:\n",
    "[![VN16IS.md.png](https://s2.ax1x.com/2019/06/05/VN16IS.md.png)](https://imgchr.com/i/VN16IS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step5: Fitting a polynomial to the lane\n",
    "In order to fit a polynomial to the lane line, I transformed the warpped image to histogram and employed windows slide method to detect the lane line. The maximum peak in the bottom of the histogram is detected as the start of lane line, Then we can search for the curve of lane line and fit a quadratic polynomial. This method output such result in a test image:\n",
    "[![VN1gPg.md.png](https://s2.ax1x.com/2019/06/05/VN1gPg.md.png)](https://imgchr.com/i/VN1gPg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step6: Compute the curvature radius and the position of the vehicle\n",
    "After acquring the parameters of a polynomical, we can use the mathmetical formation to compute the radisu of curvature of the lane. Assuming the camera was installed in the middle of the vehicle, we can also get the position of the car relative to the center of the lane line. Here is a result of a test image.\n",
    "[![VN1R2j.md.png](https://s2.ax1x.com/2019/06/05/VN1R2j.md.png)](https://imgchr.com/i/VN1R2j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step7&8: Video production\n",
    "Using the pipeline described above, we can ovtain the output video by applying the processes on each frame.\n",
    "The result is in CarND- Advanced Lane Finding.ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "The pipeline discussed above is a simaple and fast method to detect tlane lines but the resukt is not robust and reliable when performing at the challenge video. The shadow line and diffeent lightness condition are quite tricky to be filtered for me. I think more computer vision knowledege is needed to get more robust method. I also think deep learning model is also a good choice for lane line detection as long as enough training data can be accquired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
